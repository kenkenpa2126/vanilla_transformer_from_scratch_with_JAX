# Transformers from scratch with JAX/Flax
 This is a tutorial for understanding Transformer Models and how to modeling them with JAX/Flax!
 
## Contents
### 1. *Vanilla* Transformer [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kenkenpa2126/Transformers_from_scratch_with_JAX-Flax/blob/main/VanillaTransformer/VanillaTransformer.ipynb) 
  - As a first step, this notebook shows the implementation of *Vanilla* Transformer. 
    1. Implement *Vanilla* Transformer from scratch.
    1. Using the Multi30k dataset, train Transformer to translate German to English.
    1. Translate some sentences with a greedy search translator.
    1. Plot attention matrices.
  - Detailed explanation Blog Post (ja): [JAX/Flaxでゼロから作るTransformer① ―Vanilla Transformer](https://t.co/SGusJDfmil)
  - Detailed explanation Blog Post (en): [Transformers from scratch with JAX/Flax① ―Vanilla Transformer](https://izmyon.hatenablog.com/entry/2023/03/13/222823)

### 2. GPT
Comming Soon...

### 3. InstructGPT
Comming Soon...

### 4. Diffusion Transformer
Comming Soon...
